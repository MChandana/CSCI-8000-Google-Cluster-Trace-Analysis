{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math as math\n",
    "import glob\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12210234, 14)\n"
     ]
    }
   ],
   "source": [
    "df=pd.concat([pd.read_csv(f, compression=\"gzip\", header=None, usecols=[5,6,7,8,9,10,11,12,13,14,15,16,18,19]) for f in glob.glob(r\"C:\\Users\\so51713\\Documents\\GoogleCloudDS\\task_usage1\\part-00*.csv.gz\")])\n",
    "df.columns=[ 'MeanCPUUsage', 'CanMemUsage','AssgnMemUsage','UnmapPCMemUsage','TotalPCMemUsage','MaxMemUsage','MeanDIOTime','MeanLocalDiskUsed','MaxCPUUsage','MaxDIOTime','CPI','MAI','AggType','SamplCPUUsage']\n",
    "print(df.shape)\n",
    "\n",
    "# df=pd.concat([pd.read_csv(f, compression=\"gzip\", header=None, usecols=[5,6,8,9,12,13,14,15,16,18,19]) for f in glob.glob(r\"C:\\Users\\so51713\\Documents\\GoogleCloudDS\\task_usage1\\part-00*.csv.gz\")])\n",
    "# df.columns=[ 'MeanCPUUsage', 'CanMemUsage','UnmapPCMemUsage','TotalPCMemUsage','MeanLocalDiskUsed','MaxCPUUsage','MaxDIOTime','CPI','MAI','AggType','SamplCPUUsage']\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10262355, 14)\n"
     ]
    }
   ],
   "source": [
    "nonEmptyDF=df.dropna()\n",
    "print(nonEmptyDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.562e-03 6.787e-02 7.568e-02 ... 7.243e-03 1.000e+00 0.000e+00]\n",
      " [1.568e-03 6.787e-02 7.556e-02 ... 5.791e-03 1.000e+00 0.000e+00]\n",
      " [3.071e-04 8.044e-02 9.521e-02 ... 2.080e-02 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.364e-04 2.670e-05 0.000e+00 ... 1.064e-03 0.000e+00 0.000e+00]\n",
      " [1.460e-02 3.475e-03 4.517e-03 ... 3.184e-03 0.000e+00 2.481e-02]\n",
      " [1.488e-02 3.075e-03 4.005e-03 ... 1.176e-03 0.000e+00 3.525e-03]]\n",
      "[2.445  2.1    5.588  ... 1.067  1.542  0.9734]\n"
     ]
    }
   ],
   "source": [
    "#Define X,Y\n",
    "X=nonEmptyDF.drop(nonEmptyDF.columns[[10]], axis=1).values\n",
    "Y=nonEmptyDF.iloc[:,10].values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.977  3.596 24.15  ...  7.257  1.78   1.504]\n",
      "[ 9.775  4.012 24.75  ...  7.473  1.751  1.478]\n"
     ]
    }
   ],
   "source": [
    "# Create training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minMaxScaler_X1 = MinMaxScaler()\n",
    "X_train = minMaxScaler_X1.fit_transform(X_train)\n",
    "X_test= minMaxScaler_X1.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model1=DecisionTreeRegressor(random_state=9)\n",
    "model1.fit(X_train,Y_train)\n",
    "Y_pred=model1.predict(X_test)\n",
    "print(Y_pred)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.19\n"
     ]
    }
   ],
   "source": [
    "errors = abs(Y_pred - Y_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.63 %.\n"
     ]
    }
   ],
   "source": [
    "mape = 100 * (errors / Y_test)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87476129 0.99174115 0.99336052 0.99322442 0.98000786 0.98926834\n",
      " 0.99349771 0.99294261 0.9915249  0.99102464]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model2 = make_pipeline(MinMaxScaler(), DecisionTreeRegressor())\n",
    "scoring = 'r2'\n",
    "results=cross_val_score(model2,X, Y, cv=10,scoring=scoring)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9791353436765233\n"
     ]
    }
   ],
   "source": [
    "print(results.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
